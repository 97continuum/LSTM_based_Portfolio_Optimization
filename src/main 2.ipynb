{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import helper functions\n",
    "from helper import create_df_per_stock\n",
    "from helper import run_for_stocks\n",
    "from helper import get_best_configuration\n",
    "from helper import final_df_cleaning\n",
    "from helper import create_return_arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>datadate</th>\n",
       "      <th>tic</th>\n",
       "      <th>cshtrm</th>\n",
       "      <th>prccm</th>\n",
       "      <th>prchm</th>\n",
       "      <th>prclm</th>\n",
       "      <th>trt1m</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>evm</th>\n",
       "      <th>...</th>\n",
       "      <th>high_low_ratio</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MA_3</th>\n",
       "      <th>price_to_MA_3</th>\n",
       "      <th>return_momentum_6m</th>\n",
       "      <th>MA_6</th>\n",
       "      <th>return_momentum_9m</th>\n",
       "      <th>MA_9</th>\n",
       "      <th>return_momentum_12m</th>\n",
       "      <th>MA_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.057669</td>\n",
       "      <td>0.050441</td>\n",
       "      <td>0.047726</td>\n",
       "      <td>0.048270</td>\n",
       "      <td>0.449252</td>\n",
       "      <td>0.657229</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020950</td>\n",
       "      <td>0.599129</td>\n",
       "      <td>0.050675</td>\n",
       "      <td>0.673276</td>\n",
       "      <td>0.278596</td>\n",
       "      <td>0.050655</td>\n",
       "      <td>0.346955</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>0.203680</td>\n",
       "      <td>0.044979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>2011-04-30</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.052030</td>\n",
       "      <td>0.052741</td>\n",
       "      <td>0.479247</td>\n",
       "      <td>0.657454</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020388</td>\n",
       "      <td>0.647066</td>\n",
       "      <td>0.053232</td>\n",
       "      <td>0.698572</td>\n",
       "      <td>0.291211</td>\n",
       "      <td>0.052154</td>\n",
       "      <td>0.350194</td>\n",
       "      <td>0.049443</td>\n",
       "      <td>0.222852</td>\n",
       "      <td>0.046454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>2011-05-31</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.051408</td>\n",
       "      <td>0.055111</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.057432</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.657571</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>0.669937</td>\n",
       "      <td>0.055518</td>\n",
       "      <td>0.671418</td>\n",
       "      <td>0.270170</td>\n",
       "      <td>0.053198</td>\n",
       "      <td>0.327768</td>\n",
       "      <td>0.051806</td>\n",
       "      <td>0.249207</td>\n",
       "      <td>0.048244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.046094</td>\n",
       "      <td>0.057310</td>\n",
       "      <td>0.054270</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.449368</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022005</td>\n",
       "      <td>0.668990</td>\n",
       "      <td>0.057899</td>\n",
       "      <td>0.669438</td>\n",
       "      <td>0.275018</td>\n",
       "      <td>0.054399</td>\n",
       "      <td>0.255807</td>\n",
       "      <td>0.053366</td>\n",
       "      <td>0.306600</td>\n",
       "      <td>0.050637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>190</td>\n",
       "      <td>2011-07-31</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.062395</td>\n",
       "      <td>0.059825</td>\n",
       "      <td>0.061283</td>\n",
       "      <td>0.479955</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017924</td>\n",
       "      <td>0.721217</td>\n",
       "      <td>0.060509</td>\n",
       "      <td>0.699107</td>\n",
       "      <td>0.333047</td>\n",
       "      <td>0.056992</td>\n",
       "      <td>0.267572</td>\n",
       "      <td>0.055250</td>\n",
       "      <td>0.309609</td>\n",
       "      <td>0.053266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    datadate   tic    cshtrm     prccm     prchm     prclm     trt1m  \\\n",
       "0     22  2011-03-31  AMZN  0.057669  0.050441  0.047726  0.048270  0.449252   \n",
       "1     64  2011-04-30  AMZN  0.055855  0.054863  0.052030  0.052741  0.479247   \n",
       "2    106  2011-05-31  AMZN  0.051408  0.055111  0.054307  0.057432  0.427200   \n",
       "3    148  2011-06-30  AMZN  0.046094  0.057310  0.054270  0.054622  0.449368   \n",
       "4    190  2011-07-31  AMZN  0.044648  0.062395  0.059825  0.061283  0.479955   \n",
       "\n",
       "      CAPEI       evm  ...  high_low_ratio    RSI_14      MA_3  price_to_MA_3  \\\n",
       "0  0.657229  0.104348  ...        0.020950  0.599129  0.050675       0.673276   \n",
       "1  0.657454  0.104348  ...        0.020388  0.647066  0.053232       0.698572   \n",
       "2  0.657571  0.104227  ...        0.010842  0.669937  0.055518       0.671418   \n",
       "3  0.657700  0.104227  ...        0.022005  0.668990  0.057899       0.669438   \n",
       "4  0.657969  0.104227  ...        0.017924  0.721217  0.060509       0.699107   \n",
       "\n",
       "   return_momentum_6m      MA_6  return_momentum_9m      MA_9  \\\n",
       "0            0.278596  0.050655            0.346955  0.046881   \n",
       "1            0.291211  0.052154            0.350194  0.049443   \n",
       "2            0.270170  0.053198            0.327768  0.051806   \n",
       "3            0.275018  0.054399            0.255807  0.053366   \n",
       "4            0.333047  0.056992            0.267572  0.055250   \n",
       "\n",
       "   return_momentum_12m     MA_12  \n",
       "0             0.203680  0.044979  \n",
       "1             0.222852  0.046454  \n",
       "2             0.249207  0.048244  \n",
       "3             0.306600  0.050637  \n",
       "4             0.309609  0.053266  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/normalized_data.csv\") # Load Dataset from File generated previously. \n",
    "data = final_df_cleaning(data) # Drop unnecessary columns and arrange data by ticker and dates\n",
    "tickers = data['tic'].unique() # Create a List of the Unique Stock Tickers\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talhajamal/Library/Mobile Documents/com~apple~CloudDocs/Documents/Imperial/Courses/Semester 3/Big Data 2/BDF2/Coursework2/src/helper.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['trt1m'] = df['trt1m'].shift(-1) # Shift Target Return up\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold dataframe for each stock\n",
    "df_per_stock = create_df_per_stock(tickers=tickers, dataframe=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run for All Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AMZN', 'AVY', 'AXON', 'BBWI', 'BKNG', 'BLDR', 'CBRE', 'CDNS',\n",
       "       'CE', 'CF', 'CHD', 'CMCSA', 'CMS', 'CNC', 'COST', 'DECK', 'DLTR',\n",
       "       'EA', 'EQIX', 'FI', 'FICO', 'GOOGL', 'INCY', 'LULU', 'MA', 'MOH',\n",
       "       'NDAQ', 'NI', 'NVDA', 'ODFL', 'OKE', 'PKG', 'SBAC', 'STLD', 'TDG',\n",
       "       'TGT', 'TYL', 'UNH', 'URI', 'V', 'VLO', 'WST'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with small list\n",
    "param_grid = {\n",
    "    'lstm_units': [100, 150],\n",
    "    'dense_units1': [50, 100, 150],\n",
    "    'dense_units2': [50, 75],\n",
    "    'batch_size': [32, 64],\n",
    "    'optimizer': ['adam']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing stock: AMZN\n",
      "Hyperparameter Tuning Results already exist for AMZN. Loading existing results.\n",
      "Training and evaluating the best model for AMZN.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1287 - mse: 0.1287\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0042 - mse: 0.0042\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026 - mse: 0.0026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "For Stock AMZN the MSE is 0.005163612552891901\n",
      "Predicted results for AMZN saved.\n",
      "Processing stock: AVY\n",
      "Hyperparameter Tuning Results already exist for AVY. Loading existing results.\n",
      "Training and evaluating the best model for AVY.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0441 - mse: 0.0441\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0047 - mse: 0.0047 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - mse: 0.0015        \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - mse: 0.0018\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0019 - mse: 0.0019\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "For Stock AVY the MSE is 0.0026437730325927855\n",
      "Predicted results for AVY saved.\n",
      "Processing stock: AXON\n",
      "Hyperparameter Tuning Results already exist for AXON. Loading existing results.\n",
      "Training and evaluating the best model for AXON.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1557 - mse: 0.1557\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0209 - mse: 0.0209\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0134 - mse: 0.0134\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0090 - mse: 0.0090\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0100 - mse: 0.0100\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0083 - mse: 0.0083\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0088 - mse: 0.0088\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0090 - mse: 0.0090\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "For Stock AXON the MSE is 0.005504256945490875\n",
      "Predicted results for AXON saved.\n",
      "Processing stock: BBWI\n",
      "Hyperparameter Tuning Results already exist for BBWI. Loading existing results.\n",
      "Training and evaluating the best model for BBWI.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1121 - mse: 0.1121\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0193 - mse: 0.0193 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0096 - mse: 0.0096\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0117 - mse: 0.0117\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0122 - mse: 0.0122\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0072 - mse: 0.0072\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0068 - mse: 0.0068\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0066 - mse: 0.0066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "For Stock BBWI the MSE is 0.010137293956117665\n",
      "Predicted results for BBWI saved.\n",
      "Processing stock: BKNG\n",
      "Hyperparameter Tuning Results already exist for BKNG. Loading existing results.\n",
      "Training and evaluating the best model for BKNG.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1392 - mse: 0.1392\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0205 - mse: 0.0205 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0116 - mse: 0.0116\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0041 - mse: 0.0041\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0033 - mse: 0.0033\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x35bfd32e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "For Stock BKNG the MSE is 0.004283712503230941\n",
      "Predicted results for BKNG saved.\n",
      "Processing stock: BLDR\n",
      "Hyperparameter Tuning Results already exist for BLDR. Loading existing results.\n",
      "Training and evaluating the best model for BLDR.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0653 - mse: 0.0653\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0137 - mse: 0.0137 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0133 - mse: 0.0133\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0095 - mse: 0.0095\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0103 - mse: 0.0103\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0131 - mse: 0.0131\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0091 - mse: 0.0091\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0093 - mse: 0.0093\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0094 - mse: 0.0094\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x35eb894e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "For Stock BLDR the MSE is 0.008308948737473168\n",
      "Predicted results for BLDR saved.\n",
      "Processing stock: CBRE\n",
      "Hyperparameter Tuning Results already exist for CBRE. Loading existing results.\n",
      "Training and evaluating the best model for CBRE.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1236 - mse: 0.1236\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0093 - mse: 0.0093 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0047 - mse: 0.0047\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0029 - mse: 0.0029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "For Stock CBRE the MSE is 0.0047914265056570775\n",
      "Predicted results for CBRE saved.\n",
      "Processing stock: CDNS\n",
      "Hyperparameter Tuning Results already exist for CDNS. Loading existing results.\n",
      "Training and evaluating the best model for CDNS.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2097 - mse: 0.2097\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0139 - mse: 0.0139 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0020 - mse: 0.0020\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "For Stock CDNS the MSE is 0.002825938207803769\n",
      "Predicted results for CDNS saved.\n",
      "Processing stock: CE\n",
      "Hyperparameter Tuning Results already exist for CE. Loading existing results.\n",
      "Training and evaluating the best model for CE.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0686 - mse: 0.0686\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0102 - mse: 0.0102 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0080 - mse: 0.0080\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - mse: 0.0048\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0025 - mse: 0.0025\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0027 - mse: 0.0027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "For Stock CE the MSE is 0.005457644641676289\n",
      "Predicted results for CE saved.\n",
      "Processing stock: CF\n",
      "Hyperparameter Tuning Results already exist for CF. Loading existing results.\n",
      "Training and evaluating the best model for CF.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1352 - mse: 0.1352\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0138 - mse: 0.0138 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0074 - mse: 0.0074\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0067 - mse: 0.0067\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0045 - mse: 0.0045\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0052 - mse: 0.0052\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0040 - mse: 0.0040\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0043 - mse: 0.0043\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0038 - mse: 0.0038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "For Stock CF the MSE is 0.005109901207382741\n",
      "Predicted results for CF saved.\n",
      "Processing stock: CHD\n",
      "Hyperparameter Tuning Results already exist for CHD. Loading existing results.\n",
      "Training and evaluating the best model for CHD.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0998 - mse: 0.0998\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0185 - mse: 0.0185 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0053 - mse: 0.0053\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0044 - mse: 0.0044\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mse: 0.0012        \n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - mse: 0.0012        \n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mse: 0.0012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "For Stock CHD the MSE is 0.0016012811768787486\n",
      "Predicted results for CHD saved.\n",
      "Processing stock: CMCSA\n",
      "Hyperparameter Tuning Results already exist for CMCSA. Loading existing results.\n",
      "Training and evaluating the best model for CMCSA.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0597 - mse: 0.0597\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0061 - mse: 0.0061 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0046 - mse: 0.0046\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 - mse: 0.0013\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - mse: 0.0016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "For Stock CMCSA the MSE is 0.0031158892812085553\n",
      "Predicted results for CMCSA saved.\n",
      "Processing stock: CMS\n",
      "Hyperparameter Tuning Results already exist for CMS. Loading existing results.\n",
      "Best Configuration for CMS not found in best_configuration.csv\n",
      "Processing stock: CNC\n",
      "Hyperparameter Tuning Results already exist for CNC. Loading existing results.\n",
      "Best Configuration for CNC not found in best_configuration.csv\n",
      "Processing stock: COST\n",
      "Hyperparameter Tuning Results already exist for COST. Loading existing results.\n",
      "Best Configuration for COST not found in best_configuration.csv\n",
      "Processing stock: DECK\n",
      "Hyperparameter Tuning Results already exist for DECK. Loading existing results.\n",
      "Best Configuration for DECK not found in best_configuration.csv\n",
      "Processing stock: DLTR\n",
      "Hyperparameter Tuning Results already exist for DLTR. Loading existing results.\n",
      "Best Configuration for DLTR not found in best_configuration.csv\n",
      "Processing stock: EA\n",
      "Hyperparameter Tuning Results already exist for EA. Loading existing results.\n",
      "Best Configuration for EA not found in best_configuration.csv\n",
      "Processing stock: EQIX\n",
      "Hyperparameter Tuning Results already exist for EQIX. Loading existing results.\n",
      "Best Configuration for EQIX not found in best_configuration.csv\n",
      "Processing stock: FI\n",
      "Hyperparameter Tuning Results already exist for FI. Loading existing results.\n",
      "Best Configuration for FI not found in best_configuration.csv\n",
      "Processing stock: FICO\n",
      "Hyperparameter Tuning Results already exist for FICO. Loading existing results.\n",
      "Best Configuration for FICO not found in best_configuration.csv\n",
      "Processing stock: GOOGL\n",
      "Hyperparameter Tuning Results already exist for GOOGL. Loading existing results.\n",
      "Best Configuration for GOOGL not found in best_configuration.csv\n",
      "Processing stock: INCY\n",
      "Hyperparameter Tuning Results already exist for INCY. Loading existing results.\n",
      "Best Configuration for INCY not found in best_configuration.csv\n",
      "Processing stock: LULU\n",
      "Hyperparameter Tuning Results already exist for LULU. Loading existing results.\n",
      "Best Configuration for LULU not found in best_configuration.csv\n",
      "Processing stock: MA\n",
      "Hyperparameter Tuning Results already exist for MA. Loading existing results.\n",
      "Best Configuration for MA not found in best_configuration.csv\n",
      "Processing stock: MOH\n",
      "Hyperparameter Tuning Results already exist for MOH. Loading existing results.\n",
      "Best Configuration for MOH not found in best_configuration.csv\n",
      "Processing stock: NDAQ\n",
      "Hyperparameter Tuning Results already exist for NDAQ. Loading existing results.\n",
      "Best Configuration for NDAQ not found in best_configuration.csv\n",
      "Processing stock: NI\n",
      "Hyperparameter Tuning Results already exist for NI. Loading existing results.\n",
      "Best Configuration for NI not found in best_configuration.csv\n",
      "Processing stock: NVDA\n",
      "Hyperparameter Tuning Results already exist for NVDA. Loading existing results.\n",
      "Best Configuration for NVDA not found in best_configuration.csv\n",
      "Processing stock: ODFL\n",
      "Hyperparameter Tuning Results already exist for ODFL. Loading existing results.\n",
      "Best Configuration for ODFL not found in best_configuration.csv\n",
      "Processing stock: OKE\n",
      "Hyperparameter Tuning Results already exist for OKE. Loading existing results.\n",
      "Best Configuration for OKE not found in best_configuration.csv\n",
      "Processing stock: PKG\n",
      "Hyperparameter Tuning Results already exist for PKG. Loading existing results.\n",
      "Best Configuration for PKG not found in best_configuration.csv\n",
      "Processing stock: SBAC\n",
      "Hyperparameter Tuning Results already exist for SBAC. Loading existing results.\n",
      "Best Configuration for SBAC not found in best_configuration.csv\n",
      "Processing stock: STLD\n",
      "Hyperparameter Tuning Results already exist for STLD. Loading existing results.\n",
      "Best Configuration for STLD not found in best_configuration.csv\n",
      "Processing stock: TDG\n",
      "Hyperparameter Tuning Results already exist for TDG. Loading existing results.\n",
      "Best Configuration for TDG not found in best_configuration.csv\n",
      "Processing stock: TGT\n",
      "Running hyperparameter tuning for TGT.\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0042\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0040\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0034\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0033\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0042\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0047\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0047\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0037\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0030\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0040\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0032\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0031\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0069\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0077\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0044\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0040\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0041\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0045\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0045\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0044\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0034\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0040\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0056\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0042\n",
      "Results saved to ../results/TGT_hyperparameter_tuning_results.csv\n",
      "Best Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Best Validation MSE: 0.0030\n",
      "Training and evaluating the best model for TGT.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0685 - mse: 0.0685\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0049 - mse: 0.0049 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0034 - mse: 0.0034\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029 - mse: 0.0029\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0032 - mse: 0.0032\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0027 - mse: 0.0027\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0025 - mse: 0.0025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "For Stock TGT the MSE is 0.0041734053945934714\n",
      "Predicted results for TGT saved.\n",
      "Processing stock: TYL\n",
      "Running hyperparameter tuning for TYL.\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0028\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0031\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0027\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0033\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0040\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0028\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0060\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0029\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0032\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0031\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0027\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0035\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0073\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0046\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0051\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0048\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0045\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0046\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0041\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0059\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0032\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0038\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0037\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0049\n",
      "Results saved to ../results/TYL_hyperparameter_tuning_results.csv\n",
      "Best Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Best Validation MSE: 0.0027\n",
      "Training and evaluating the best model for TYL.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1215 - mse: 0.1215\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0063 - mse: 0.0063 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0043 - mse: 0.0043 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0021 - mse: 0.0021\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026 - mse: 0.0026\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0026 - mse: 0.0026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "For Stock TYL the MSE is 0.003985705472580529\n",
      "Predicted results for TYL saved.\n",
      "Processing stock: UNH\n",
      "Running hyperparameter tuning for UNH.\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0017\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0022\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0023\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0017\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0028\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0030\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0022\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0030\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0023\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0018\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0021\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0020\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0040\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0052\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0038\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0028\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0046\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0024\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0020\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0044\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0032\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0026\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0041\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0025\n",
      "Results saved to ../results/UNH_hyperparameter_tuning_results.csv\n",
      "Best Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Best Validation MSE: 0.0017\n",
      "Training and evaluating the best model for UNH.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1732 - mse: 0.1732\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - mse: 0.0114 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0031 - mse: 0.0031\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - mse: 0.0015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "For Stock UNH the MSE is 0.0009289382103655494\n",
      "Predicted results for UNH saved.\n",
      "Processing stock: URI\n",
      "Running hyperparameter tuning for URI.\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0078\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0068\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0070\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0089\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0071\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0058\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0057\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0089\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0078\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0079\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0067\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0081\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0082\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0105\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0079\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0072\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0067\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0072\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0076\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0060\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0087\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0068\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0079\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0087\n",
      "Results saved to ../results/URI_hyperparameter_tuning_results.csv\n",
      "Best Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Best Validation MSE: 0.0057\n",
      "Training and evaluating the best model for URI.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0495 - mse: 0.0495\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0089 - mse: 0.0089\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0078 - mse: 0.0078 \n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0055 - mse: 0.0055\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0056 - mse: 0.0056\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0062 - mse: 0.0062\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - mse: 0.0054\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0057 - mse: 0.0057\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0057 - mse: 0.0057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "For Stock URI the MSE is 0.009647487444137308\n",
      "Predicted results for URI saved.\n",
      "Processing stock: V\n",
      "Running hyperparameter tuning for V.\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0023\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0026\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0018\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0016\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0020\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0031\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0037\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0027\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0016\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0020\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0029\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0034\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0029\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0031\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0045\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0043\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0048\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0032\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0017\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0059\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0037\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0034\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0040\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0033\n",
      "Results saved to ../results/V_hyperparameter_tuning_results.csv\n",
      "Best Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Best Validation MSE: 0.0016\n",
      "Training and evaluating the best model for V.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0990 - mse: 0.0990\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 - mse: 0.0018 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 - mse: 0.0019 \n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0022 - mse: 0.0022\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012 - mse: 0.0012        \n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014 - mse: 0.0014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "For Stock V the MSE is 0.0021113984713532034\n",
      "Predicted results for V saved.\n",
      "Processing stock: VLO\n",
      "Running hyperparameter tuning for VLO.\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0076\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0069\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0063\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0060\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0068\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0070\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0077\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0061\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0073\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0067\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0097\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0067\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0101\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0065\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0068\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0072\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0093\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0090\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0096\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0063\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0097\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0071\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0074\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0081\n",
      "Results saved to ../results/VLO_hyperparameter_tuning_results.csv\n",
      "Best Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Best Validation MSE: 0.0060\n",
      "Training and evaluating the best model for VLO.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1878 - mse: 0.1878\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0184 - mse: 0.0184\n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0079 - mse: 0.0079\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0070 - mse: 0.0070 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0061 - mse: 0.0061\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0071 - mse: 0.0071\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0064 - mse: 0.0064\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0063 - mse: 0.0063\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0058 - mse: 0.0058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "For Stock VLO the MSE is 0.004739661481954001\n",
      "Predicted results for VLO saved.\n",
      "Processing stock: WST\n",
      "Running hyperparameter tuning for WST.\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0032\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0031\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0025\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0036\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0052\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0038\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0026\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0030\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0031\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0047\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0049\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 32, 'optimizer': 'adam'}, Average Validation MSE: 0.0038\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0047\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0059\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0058\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0036\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0038\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 100, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0036\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0050\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 50, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0047\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0038\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 100, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0028\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 50, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0055\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Current Parameters: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}\n",
      "Params: {'lstm_units': 150, 'dense_units1': 150, 'dense_units2': 75, 'batch_size': 64, 'optimizer': 'adam'}, Average Validation MSE: 0.0038\n",
      "Results saved to ../results/WST_hyperparameter_tuning_results.csv\n",
      "Best Params: {'lstm_units': 100, 'dense_units1': 100, 'dense_units2': 50, 'batch_size': 32, 'optimizer': 'adam'}, Best Validation MSE: 0.0025\n",
      "Training and evaluating the best model for WST.\n",
      "Epoch 1/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1459 - mse: 0.1459\n",
      "Epoch 2/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0144 - mse: 0.0144 \n",
      "Epoch 3/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0081 - mse: 0.0081\n",
      "Epoch 4/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0047 - mse: 0.0047 \n",
      "Epoch 5/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0037 - mse: 0.0037\n",
      "Epoch 6/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 7/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0035 - mse: 0.0035\n",
      "Epoch 8/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 9/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 10/10\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0022 - mse: 0.0022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "For Stock WST the MSE is 0.004652554375412884\n",
      "Predicted results for WST saved.\n",
      "Best configurations for all stocks saved.\n"
     ]
    }
   ],
   "source": [
    "models = run_for_stocks(tickers, df_per_stock, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Best Configuration for each stock via the CSV files\n",
    "best_configurations = get_best_configuration(tickers=tickers)\n",
    "best_configurations_df = pd.DataFrame(best_configurations).T.reset_index()\n",
    "best_configurations_df.columns = ['ticker', 'lstm_units', 'dense_units1', 'dense_units2', 'batch_size', 'optimizer', 'avg_val_mse']\n",
    "best_configurations_df\n",
    "best_configurations_df.to_csv(\"../results/best_configs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Numpy Array of Returns\n",
    "normalized_12_m_default_lstm_no_burning_window_X = create_return_arrays(tickers=tickers,\n",
    "                                                                        folder=\"../normalized_returns_default_lstm_no_burning_window\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_861\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_861\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1722 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1723 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2583 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2584 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,050</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2585 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_1722 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m65,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1723 (\u001b[38;5;33mLSTM\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m80,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2583 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m10,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2584 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m5,050\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2585 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,201</span> (629.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m161,201\u001b[0m (629.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,201</span> (629.69 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m161,201\u001b[0m (629.69 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models['V'].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance Matrix via Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use below Data for Presentation Slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of X Features is: (154, 63)\n",
      "The Shape of y Features is: (154,)\n"
     ]
    }
   ],
   "source": [
    "# Lets first try to get the model to run for 1 stock\n",
    "amzn = data[data['tic'] == 'AMZN'].iloc[:, 1:]\n",
    "y = amzn['trt1m'].values\n",
    "amzn.drop(columns=['trt1m'], inplace=True)\n",
    "X = amzn.iloc[:, 2:].values\n",
    "print(f\"The Shape of X Features is: {X.shape}\")\n",
    "print(f\"The Shape of y Features is: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of X Features is: (142, 12, 63)\n",
      "The Shape of y Features is: (142,)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 12 # Feed past 12 month returns into sequence for LSTM\n",
    "# Converting Features into 3D space for LSTM to add a time component\n",
    "X_features, y_target = [], []\n",
    "for i in range(X.shape[0] - sequence_length):\n",
    "    X_features.append(X[i:i+sequence_length])\n",
    "    y_target.append(y[i + sequence_length])\n",
    "X_features = np.array(X_features)\n",
    "y_target = np.array(y_target)\n",
    "\n",
    "print(f\"The Shape of X Features is: {X_features.shape}\")\n",
    "print(f\"The Shape of y Features is: {y_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of my training set will be : 123 and the test set will be : 31\n",
      "Shape of X_train: (123, 12, 63)\n",
      "Shape of y_train: (123,)\n",
      "Shape of X_test: (19, 12, 63)\n",
      "Shape of y_test: (19,)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(amzn) * 0.8)\n",
    "print(f\"The size of my training set will be : {train_size} and the test set will be : {int(len(amzn)) - train_size}\")\n",
    "X_train, y_train = X_features[:train_size], y_target[:train_size]\n",
    "y_train.reshape(-1, 1)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "X_test, y_test = X_features[train_size:], y_target[train_size:]\n",
    "y_target.reshape(-1, 1)\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data['AMZN']['trt1m'], label='AMZN Standardized Returns')\n",
    "plt.plot(df_per_stock['AMZN']['trt1m'][-19:], label='Returns I want to predict')\n",
    "plt.title(f'Amazon Standardized Returns')\n",
    "plt.xlabel('Days')\n",
    "plt.ylabel('Returns')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models['AMZN'].plot_performance()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
