{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import Functions needed for Data Preprocessing\n",
    "from data import ( preprocess_stock_data,\n",
    "                  clean_financial_ratios,\n",
    "                  merge_and_clean_data,\n",
    "                  filter_useful_features,\n",
    "                  calculate_technical_indicators,\n",
    "                  normalize_data,\n",
    "                  merge_macro_data)\n",
    "\n",
    "# import helper functions to run LSTM Training and Predictions\n",
    "from helper import (create_df_per_stock,\n",
    "                    run_for_stocks,\n",
    "                    get_best_configuration,\n",
    "                    final_df_cleaning,\n",
    "                    create_return_arrays,\n",
    "                    create_returns_for_cov, \n",
    "                    calculate_covariance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "stock = pd.read_csv('../data/stocks_1.csv')\n",
    "stock_factor = pd.read_csv('../data/ratios_2.csv')\n",
    "macro = pd.read_csv('../data/bond_and_cpi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stocks\n",
    "stock_avg = preprocess_stock_data(stock)\n",
    "# Clean financial ratios data\n",
    "stock_factor_1 = clean_financial_ratios(stock_avg, stock_factor)\n",
    "# Merge trading data and financial ratios data and select proper companies\n",
    "stock_all_final = merge_and_clean_data(stock_avg, stock_factor_1)\n",
    "# Select features that are meaningful and useful\n",
    "stock_final = filter_useful_features(stock_all_final)\n",
    "# Calculate momentum technical indicators\n",
    "stock_final_1 = stock_final.groupby('gvkey').apply(calculate_technical_indicators).reset_index(drop=True)\n",
    "stock_use = stock_final_1.dropna()\n",
    "# Merge macro data\n",
    "stock_use = merge_macro_data(stock_use, macro)\n",
    "# Normalization\n",
    "stock_n = normalize_data(stock_use)\n",
    "# Save to CSV\n",
    "stock_n.to_csv('../data/normalized_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>datadate</th>\n",
       "      <th>tic</th>\n",
       "      <th>cshtrm</th>\n",
       "      <th>prccm</th>\n",
       "      <th>prchm</th>\n",
       "      <th>prclm</th>\n",
       "      <th>trt1m</th>\n",
       "      <th>CAPEI</th>\n",
       "      <th>evm</th>\n",
       "      <th>...</th>\n",
       "      <th>b30ret</th>\n",
       "      <th>b20ret</th>\n",
       "      <th>b10ret</th>\n",
       "      <th>b7ret</th>\n",
       "      <th>b5ret</th>\n",
       "      <th>b2ret</th>\n",
       "      <th>b1ret</th>\n",
       "      <th>t90ret</th>\n",
       "      <th>t30ret</th>\n",
       "      <th>cpiret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3388</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.057669</td>\n",
       "      <td>0.050441</td>\n",
       "      <td>0.047726</td>\n",
       "      <td>0.048270</td>\n",
       "      <td>0.449252</td>\n",
       "      <td>0.657229</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447572</td>\n",
       "      <td>0.505968</td>\n",
       "      <td>0.485734</td>\n",
       "      <td>0.460448</td>\n",
       "      <td>0.479048</td>\n",
       "      <td>0.409137</td>\n",
       "      <td>0.349846</td>\n",
       "      <td>0.074603</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.009751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3389</td>\n",
       "      <td>2011-04-30</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.055855</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.052030</td>\n",
       "      <td>0.052741</td>\n",
       "      <td>0.479247</td>\n",
       "      <td>0.657454</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524495</td>\n",
       "      <td>0.625134</td>\n",
       "      <td>0.632978</td>\n",
       "      <td>0.696662</td>\n",
       "      <td>0.777043</td>\n",
       "      <td>0.612828</td>\n",
       "      <td>0.390447</td>\n",
       "      <td>0.068691</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0.006439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3390</td>\n",
       "      <td>2011-05-31</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.051408</td>\n",
       "      <td>0.055111</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.057432</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.657571</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577259</td>\n",
       "      <td>0.700208</td>\n",
       "      <td>0.734779</td>\n",
       "      <td>0.755825</td>\n",
       "      <td>0.762814</td>\n",
       "      <td>0.561705</td>\n",
       "      <td>0.414261</td>\n",
       "      <td>0.039340</td>\n",
       "      <td>0.010522</td>\n",
       "      <td>0.004704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3391</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.046094</td>\n",
       "      <td>0.057310</td>\n",
       "      <td>0.054270</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.449368</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352766</td>\n",
       "      <td>0.407129</td>\n",
       "      <td>0.432365</td>\n",
       "      <td>0.440776</td>\n",
       "      <td>0.524773</td>\n",
       "      <td>0.489151</td>\n",
       "      <td>0.358103</td>\n",
       "      <td>0.047289</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>-0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3392</td>\n",
       "      <td>2011-07-31</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.062395</td>\n",
       "      <td>0.059825</td>\n",
       "      <td>0.061283</td>\n",
       "      <td>0.479955</td>\n",
       "      <td>0.657969</td>\n",
       "      <td>0.104227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624880</td>\n",
       "      <td>0.760939</td>\n",
       "      <td>0.794987</td>\n",
       "      <td>0.803837</td>\n",
       "      <td>0.839120</td>\n",
       "      <td>0.529782</td>\n",
       "      <td>0.281747</td>\n",
       "      <td>0.009376</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    datadate   tic    cshtrm     prccm     prchm     prclm     trt1m  \\\n",
       "0   3388  2011-03-31  AMZN  0.057669  0.050441  0.047726  0.048270  0.449252   \n",
       "1   3389  2011-04-30  AMZN  0.055855  0.054863  0.052030  0.052741  0.479247   \n",
       "2   3390  2011-05-31  AMZN  0.051408  0.055111  0.054307  0.057432  0.427200   \n",
       "3   3391  2011-06-30  AMZN  0.046094  0.057310  0.054270  0.054622  0.449368   \n",
       "4   3392  2011-07-31  AMZN  0.044648  0.062395  0.059825  0.061283  0.479955   \n",
       "\n",
       "      CAPEI       evm  ...    b30ret    b20ret    b10ret     b7ret     b5ret  \\\n",
       "0  0.657229  0.104348  ...  0.447572  0.505968  0.485734  0.460448  0.479048   \n",
       "1  0.657454  0.104348  ...  0.524495  0.625134  0.632978  0.696662  0.777043   \n",
       "2  0.657571  0.104227  ...  0.577259  0.700208  0.734779  0.755825  0.762814   \n",
       "3  0.657700  0.104227  ...  0.352766  0.407129  0.432365  0.440776  0.524773   \n",
       "4  0.657969  0.104227  ...  0.624880  0.760939  0.794987  0.803837  0.839120   \n",
       "\n",
       "      b2ret     b1ret    t90ret    t30ret    cpiret  \n",
       "0  0.409137  0.349846  0.074603  0.021886  0.009751  \n",
       "1  0.612828  0.390447  0.068691  0.018939  0.006439  \n",
       "2  0.561705  0.414261  0.039340  0.010522  0.004704  \n",
       "3  0.489151  0.358103  0.047289  0.015152 -0.001071  \n",
       "4  0.529782  0.281747  0.009376  0.001894  0.000886  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/normalized_data.csv\") # Load Dataset from File generated previously. \n",
    "data = final_df_cleaning(data) # Drop unnecessary columns and arrange data by ticker and dates\n",
    "tickers = data['tic'].unique() # Create a List of the Unique Stock Tickers\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AMZN', 'AVY', 'AXON', 'BBWI', 'BKNG', 'BLDR', 'CBRE', 'CDNS',\n",
       "       'CE', 'CF', 'CHD', 'CMCSA', 'CMS', 'CNC', 'COST', 'DECK', 'DLTR',\n",
       "       'EA', 'EQIX', 'FI', 'FICO', 'GOOGL', 'INCY', 'LULU', 'MA', 'MOH',\n",
       "       'NDAQ', 'NI', 'NVDA', 'ODFL', 'OKE', 'PKG', 'SBAC', 'STLD', 'TDG',\n",
       "       'TGT', 'TYL', 'UNH', 'URI', 'V', 'VLO', 'WST'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talhajamal/Library/Mobile Documents/com~apple~CloudDocs/Documents/Imperial/Courses/Semester 3/Big Data 2/BDF2/Coursework2/src/helper.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['trt1m'] = df['trt1m'].shift(-1) # Shift Target Return up\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold dataframe for each stock\n",
    "df_per_stock = create_df_per_stock(tickers=tickers, dataframe=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning for LSTMs and Return Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with small list\n",
    "param_grid = {\n",
    "    'lstm_units': [100, 150],\n",
    "    'dense_units1': [50, 100, 150],\n",
    "    'dense_units2': [50, 75],\n",
    "    'batch_size': [32, 64],\n",
    "    'optimizer': ['adam']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Run the below command when running a new model - otherwise use the saved data within the \n",
    "# past_results folder\n",
    "\n",
    "# models = run_for_stocks(tickers, df_per_stock, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbest_configurations = get_best_configuration(tickers=tickers)\\nbest_configurations_df = pd.DataFrame(best_configurations).T.reset_index()\\nbest_configurations_df.columns = [\\'ticker\\',\\n                                  \\'lstm_units\\',\\n                                  \\'dense_units1\\',\\n                                  \\'dense_units2\\',\\n                                  \\'batch_size\\',\\n                                  \\'optimizer\\', \\n                                  \\'avg_val_mse\\']\\nbest_configurations_df\\nbest_configurations_df.to_csv(\"../results/best_configs.csv\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Best Configuration for each stock via the CSV files\n",
    "# Only run when you've finished running a new model above to confirm all best_configurations are saved\n",
    "# Otherwise use best_configs inside the past_results folder\n",
    "\"\"\"\n",
    "best_configurations = get_best_configuration(tickers=tickers)\n",
    "best_configurations_df = pd.DataFrame(best_configurations).T.reset_index()\n",
    "best_configurations_df.columns = ['ticker',\n",
    "                                  'lstm_units',\n",
    "                                  'dense_units1',\n",
    "                                  'dense_units2',\n",
    "                                  'batch_size',\n",
    "                                  'optimizer', \n",
    "                                  'avg_val_mse']\n",
    "best_configurations_df\n",
    "best_configurations_df.to_csv(\"../results/best_configs.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Numpy Array of Returns\n",
    "without_macro_features = \"../past_results/without_macro_data/\"\n",
    "with_macro_features = \"../past_results/with_macro_data/\"\n",
    "default_lstm_no_burning_window_12m = create_return_arrays(tickers=tickers,\n",
    "                                                          folder=f\"{without_macro_features}default_lstm_no_burning_window_12m\")\n",
    "default_lstm_with_burning_window_12m = create_return_arrays(tickers=tickers,\n",
    "                                                            folder=f\"{without_macro_features}default_lstm_burning_window_12m\")\n",
    "default_lstm_no_burning_window_3m = create_return_arrays(tickers=tickers,\n",
    "                                                         folder=f\"{without_macro_features}default_lstm_no_burning_window_3m\")\n",
    "default_lstm_with_burning_window_3m = create_return_arrays(tickers=tickers,\n",
    "                                                            folder=f\"{without_macro_features}default_lstm_with_burning_window_3m\")\n",
    "default_lstm_with_burning_window_6m = create_return_arrays(tickers=tickers,\n",
    "                                                           folder=f\"{without_macro_features}default_lstm_burning_window_6m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance Matrix via Shrinkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns_data_12m_no_burning_window = create_returns_for_cov(df_per_stock=df_per_stock,\n",
    "                                      return_array=default_lstm_no_burning_window_12m)\n",
    "\n",
    "returns_data_12m_with_burning_window = create_returns_for_cov(df_per_stock=df_per_stock,\n",
    "                                      return_array=default_lstm_with_burning_window_12m)\n",
    "\n",
    "returns_data_3m_no_burning_window = create_returns_for_cov(df_per_stock=df_per_stock,\n",
    "                                      return_array=default_lstm_no_burning_window_3m)\n",
    "\n",
    "returns_data_3m_with_burning_window = create_returns_for_cov(df_per_stock=df_per_stock,\n",
    "                                      return_array=default_lstm_with_burning_window_3m)\n",
    "\n",
    "returns_data_6m_with_burning_window = create_returns_for_cov(df_per_stock=df_per_stock,\n",
    "                                      return_array=default_lstm_with_burning_window_6m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrices_12m_no_burning_window, shrinkages_12m_no_burning_window = calculate_covariance_matrix(returns_data_12m_no_burning_window)\n",
    "\n",
    "cov_matrices_12m_with_burning_window, shrinkages_12m_with_burning_window = calculate_covariance_matrix(returns_data_12m_with_burning_window)\n",
    "\n",
    "cov_matrices_3m_no_burning_window, shrinkages_3m_no_burning_window = calculate_covariance_matrix(returns_data_3m_no_burning_window)\n",
    "\n",
    "cov_matrices_3m_with_burning_window, shrinkages_3m_with_burning_window = calculate_covariance_matrix(returns_data_3m_with_burning_window)\n",
    "\n",
    "cov_matrices_6m_with_burning_window, shrinkages_6m_with_burning_window = calculate_covariance_matrix(returns_data_6m_with_burning_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of 12M No Burning Window Returns: (29, 42)\n",
      "The Length of the list of Cov Matrix for 12M No Burning Window Returns: 29\n",
      "The Shape of 12M With Burning Window Returns: (19, 42)\n",
      "The Length of the list of Cov Matrix for 12M with Burning Window Returns: 19\n",
      "The Shape of 3M No Burning Window Returns: (30, 42)\n",
      "The Length of the list of Cov Matrix for 3M No Burning Window Returns: 30\n",
      "The Shape of 3M With Burning Window Returns: (28, 42)\n",
      "The Length of the list of Cov Matrix for 3M with Burning Window Returns: 28\n",
      "The Shape of 6M With Burning Window Returns: (25, 42)\n",
      "The Length of the list of Cov Matrix for 6M with Burning Window Returns: 25\n"
     ]
    }
   ],
   "source": [
    "print(f\"The Shape of 12M No Burning Window Returns: {default_lstm_no_burning_window_12m.shape}\")\n",
    "print(f\"The Length of the list of Cov Matrix for 12M No Burning Window Returns: {len(cov_matrices_12m_no_burning_window)}\")\n",
    "\n",
    "print(f\"The Shape of 12M With Burning Window Returns: {default_lstm_with_burning_window_12m.shape}\")\n",
    "print(f\"The Length of the list of Cov Matrix for 12M with Burning Window Returns: {len(cov_matrices_12m_with_burning_window)}\")\n",
    "\n",
    "print(f\"The Shape of 3M No Burning Window Returns: {default_lstm_no_burning_window_3m.shape}\")\n",
    "print(f\"The Length of the list of Cov Matrix for 3M No Burning Window Returns: {len(cov_matrices_3m_no_burning_window)}\")\n",
    "\n",
    "print(f\"The Shape of 3M With Burning Window Returns: {default_lstm_with_burning_window_3m.shape}\")\n",
    "print(f\"The Length of the list of Cov Matrix for 3M with Burning Window Returns: {len(cov_matrices_3m_with_burning_window)}\")\n",
    "\n",
    "print(f\"The Shape of 6M With Burning Window Returns: {default_lstm_with_burning_window_6m.shape}\")\n",
    "print(f\"The Length of the list of Cov Matrix for 6M with Burning Window Returns: {len(cov_matrices_6m_with_burning_window)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Variance Portfolio Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code of Kangjin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code of Kangjin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use below Data for Presentation Slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of X Features is: (154, 74)\n",
      "The Shape of y Features is: (154,)\n"
     ]
    }
   ],
   "source": [
    "# Lets first try to get the model to run for 1 stock\n",
    "amzn = data[data['tic'] == 'AMZN'].iloc[:, :]\n",
    "y = amzn['trt1m'].values\n",
    "amzn.drop(columns=['trt1m'], inplace=True)\n",
    "X = amzn.iloc[:, 2:].values\n",
    "print(f\"The Shape of X Features is: {X.shape}\")\n",
    "print(f\"The Shape of y Features is: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of X Features is: (142, 12, 74)\n",
      "The Shape of y Features is: (142,)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 12 # Feed past 12 month returns into sequence for LSTM\n",
    "# Converting Features into 3D space for LSTM to add a time component\n",
    "X_features, y_target = [], []\n",
    "for i in range(X.shape[0] - sequence_length):\n",
    "    X_features.append(X[i:i+sequence_length])\n",
    "    y_target.append(y[i + sequence_length])\n",
    "X_features = np.array(X_features)\n",
    "y_target = np.array(y_target)\n",
    "\n",
    "print(f\"The Shape of X Features is: {X_features.shape}\")\n",
    "print(f\"The Shape of y Features is: {y_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of my training set will be : 123 and the test set will be : 31\n",
      "Shape of X_train: (123, 12, 74)\n",
      "Shape of y_train: (123,)\n",
      "Shape of X_test: (19, 12, 74)\n",
      "Shape of y_test: (19,)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(amzn) * 0.8)\n",
    "print(f\"The size of my training set will be : {train_size} and the test set will be : {int(len(amzn)) - train_size}\")\n",
    "X_train, y_train = X_features[:train_size], y_target[:train_size]\n",
    "y_train.reshape(-1, 1)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "X_test, y_test = X_features[train_size:], y_target[train_size:]\n",
    "y_target.reshape(-1, 1)\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
